{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08bf105",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accbefba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'SPECIAL SECRET HEARTS:': 1, 'SECRET HEARTS: A': 1, \"HEARTS: A Child's\": 1, \"A Child's Introduction\": 1, \"Child's Introduction to\": 1, 'Introduction to Dementia': 1, 'to Dementia and': 1, 'Dementia and Pink': 1, 'and Pink Curls': 1, 'Pink Curls -': 1, 'Curls - A': 1, '- A Santa': 1, 'A Santa ...': 1, 'Santa ... -': 1, '... - http://t.co/UWCdc8FA9a': 1, '- http://t.co/UWCdc8FA9a http://t.co/meexKLGTKl': 1}\n",
      "{'RT @BuyBookstore: SPECIAL': 1, '@BuyBookstore: SPECIAL SECRET': 1, 'SPECIAL SECRET HEARTS:': 1, 'SECRET HEARTS: A': 1, \"HEARTS: A Child's\": 1, \"A Child's Introduction\": 1, \"Child's Introduction to\": 1, 'Introduction to Dementia': 1, 'to Dementia and': 1, 'Dementia and Pink': 1, 'and Pink Curls': 1, 'Pink Curls -': 1, 'Curls - A': 1, '- A Santa': 1, 'A Santa ...': 1, 'Santa ... -': 1, '... - http://t.co/UWCdc8FA9a': 1, '- http://t.co/UWCdc8FA9a http://t.Â…': 1}\n",
      "\n",
      "\n",
      "are near duplicates\n",
      "2.5724787771376323\n",
      "SPECIAL SECRET HEARTS:\n",
      "SECRET HEARTS: A\n",
      "HEARTS: A Child's\n",
      "A Child's Introduction\n",
      "Child's Introduction to\n",
      "Introduction to Dementia\n",
      "to Dementia and\n",
      "Dementia and Pink\n",
      "and Pink Curls\n",
      "Pink Curls -\n",
      "Curls - A\n",
      "- A Santa\n",
      "A Santa ...\n",
      "Santa ... -\n",
      "... - http://t.co/UWCdc8FA9a\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'\"Santa Claus Is': 1, 'Claus Is Coming': 1, 'Is Coming To': 1, 'Coming To Town': 1, 'To Town #MTVHottest': 1, 'Town #MTVHottest Justin': 1, '#MTVHottest Justin Bieber\"': 1}\n",
      "{'\"RT @DrewFtDevonne_: Rt': 1, '@DrewFtDevonne_: Rt si': 1, 'Rt si te': 1, 'si te gusta': 1, 'te gusta Santa': 1, 'gusta Santa Claus': 1, 'Santa Claus Is': 1, 'Claus Is Coming': 1, 'Is Coming To': 1, 'Coming To Town': 1, 'To Town #MTVHottest': 1, 'Town #MTVHottest Justin': 1, '#MTVHottest Justin Bieber\"': 1}\n",
      "\n",
      "\n",
      "are near duplicates\n",
      "1.3416407864998738\n",
      "Claus Is Coming\n",
      "Is Coming To\n",
      "Coming To Town\n",
      "To Town #MTVHottest\n",
      "Town #MTVHottest Justin\n",
      "#MTVHottest Justin Bieber\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'\"Santa Claus Is': 1, 'Claus Is Coming': 1, 'Is Coming To': 1, 'Coming To Town': 1, 'To Town #MTVHottest': 1, 'Town #MTVHottest Justin': 1, '#MTVHottest Justin Bieber\"': 1}\n",
      "{'\"Rt si te': 1, 'si te gusta': 1, 'te gusta Santa': 1, 'gusta Santa Claus': 1, 'Santa Claus Is': 1, 'Claus Is Coming': 1, 'Is Coming To': 1, 'Coming To Town': 1, 'To Town #MTVHottest': 1, 'Town #MTVHottest Justin': 1, '#MTVHottest Justin Bieber\"': 1}\n",
      "\n",
      "\n",
      "are near duplicates\n",
      "1.4142135623730951\n",
      "Claus Is Coming\n",
      "Is Coming To\n",
      "Coming To Town\n",
      "To Town #MTVHottest\n",
      "Town #MTVHottest Justin\n",
      "#MTVHottest Justin Bieber\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'RT @BuyBookstore: SPECIAL': 1, '@BuyBookstore: SPECIAL SECRET': 1, 'SPECIAL SECRET HEARTS:': 1, 'SECRET HEARTS: A': 1, \"HEARTS: A Child's\": 1, \"A Child's Introduction\": 1, \"Child's Introduction to\": 1, 'Introduction to Dementia': 1, 'to Dementia and': 1, 'Dementia and Pink': 1, 'and Pink Curls': 1, 'Pink Curls -': 1, 'Curls - A': 1, '- A Santa': 1, 'A Santa ...': 1, 'Santa ... -': 1, '... - http://t.co/UWCdc8FA9a': 1, '- http://t.co/UWCdc8FA9a http://t.Â…': 1}\n",
      "{'SPECIAL SECRET HEARTS:': 1, 'SECRET HEARTS: A': 1, \"HEARTS: A Child's\": 1, \"A Child's Introduction\": 1, \"Child's Introduction to\": 1, 'Introduction to Dementia': 1, 'to Dementia and': 1, 'Dementia and Pink': 1, 'and Pink Curls': 1, 'Pink Curls -': 1, 'Curls - A': 1, '- A Santa': 1, 'A Santa ...': 1, 'Santa ... -': 1, '... - http://t.co/UWCdc8FA9a': 1, '- http://t.co/UWCdc8FA9a http://t.co/meexKLGTKl': 1}\n",
      "\n",
      "\n",
      "are near duplicates\n",
      "2.5724787771376323\n",
      "SPECIAL SECRET HEARTS:\n",
      "SECRET HEARTS: A\n",
      "HEARTS: A Child's\n",
      "A Child's Introduction\n",
      "Child's Introduction to\n",
      "Introduction to Dementia\n",
      "to Dementia and\n",
      "Dementia and Pink\n",
      "and Pink Curls\n",
      "Pink Curls -\n",
      "Curls - A\n",
      "- A Santa\n",
      "A Santa ...\n",
      "Santa ... -\n",
      "... - http://t.co/UWCdc8FA9a\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'\"RT @DrewFtDevonne_: Rt': 1, '@DrewFtDevonne_: Rt si': 1, 'Rt si te': 1, 'si te gusta': 1, 'te gusta Santa': 1, 'gusta Santa Claus': 1, 'Santa Claus Is': 1, 'Claus Is Coming': 1, 'Is Coming To': 1, 'Coming To Town': 1, 'To Town #MTVHottest': 1, 'Town #MTVHottest Justin': 1, '#MTVHottest Justin Bieber\"': 1}\n",
      "{'\"Santa Claus Is': 1, 'Claus Is Coming': 1, 'Is Coming To': 1, 'Coming To Town': 1, 'To Town #MTVHottest': 1, 'Town #MTVHottest Justin': 1, '#MTVHottest Justin Bieber\"': 1}\n",
      "\n",
      "\n",
      "are near duplicates\n",
      "1.3416407864998738\n",
      "Claus Is Coming\n",
      "Is Coming To\n",
      "Coming To Town\n",
      "To Town #MTVHottest\n",
      "Town #MTVHottest Justin\n",
      "#MTVHottest Justin Bieber\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'\"RT @DrewFtDevonne_: Rt': 1, '@DrewFtDevonne_: Rt si': 1, 'Rt si te': 1, 'si te gusta': 1, 'te gusta Santa': 1, 'gusta Santa Claus': 1, 'Santa Claus Is': 1, 'Claus Is Coming': 1, 'Is Coming To': 1, 'Coming To Town': 1, 'To Town #MTVHottest': 1, 'Town #MTVHottest Justin': 1, '#MTVHottest Justin Bieber\"': 1}\n",
      "{'\"Rt si te': 1, 'si te gusta': 1, 'te gusta Santa': 1, 'gusta Santa Claus': 1, 'Santa Claus Is': 1, 'Claus Is Coming': 1, 'Is Coming To': 1, 'Coming To Town': 1, 'To Town #MTVHottest': 1, 'Town #MTVHottest Justin': 1, '#MTVHottest Justin Bieber\"': 1}\n",
      "\n",
      "\n",
      "are near duplicates\n",
      "2.041241452319315\n",
      "si te gusta\n",
      "te gusta Santa\n",
      "gusta Santa Claus\n",
      "Santa Claus Is\n",
      "Claus Is Coming\n",
      "Is Coming To\n",
      "Coming To Town\n",
      "To Town #MTVHottest\n",
      "Town #MTVHottest Justin\n",
      "#MTVHottest Justin Bieber\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'\"Rt si te': 1, 'si te gusta': 1, 'te gusta Santa': 1, 'gusta Santa Claus': 1, 'Santa Claus Is': 1, 'Claus Is Coming': 1, 'Is Coming To': 1, 'Coming To Town': 1, 'To Town #MTVHottest': 1, 'Town #MTVHottest Justin': 1, '#MTVHottest Justin Bieber\"': 1}\n",
      "{'\"Santa Claus Is': 1, 'Claus Is Coming': 1, 'Is Coming To': 1, 'Coming To Town': 1, 'To Town #MTVHottest': 1, 'Town #MTVHottest Justin': 1, '#MTVHottest Justin Bieber\"': 1}\n",
      "\n",
      "\n",
      "are near duplicates\n",
      "1.4142135623730951\n",
      "Claus Is Coming\n",
      "Is Coming To\n",
      "Coming To Town\n",
      "To Town #MTVHottest\n",
      "Town #MTVHottest Justin\n",
      "#MTVHottest Justin Bieber\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'\"Rt si te': 1, 'si te gusta': 1, 'te gusta Santa': 1, 'gusta Santa Claus': 1, 'Santa Claus Is': 1, 'Claus Is Coming': 1, 'Is Coming To': 1, 'Coming To Town': 1, 'To Town #MTVHottest': 1, 'Town #MTVHottest Justin': 1, '#MTVHottest Justin Bieber\"': 1}\n",
      "{'\"RT @DrewFtDevonne_: Rt': 1, '@DrewFtDevonne_: Rt si': 1, 'Rt si te': 1, 'si te gusta': 1, 'te gusta Santa': 1, 'gusta Santa Claus': 1, 'Santa Claus Is': 1, 'Claus Is Coming': 1, 'Is Coming To': 1, 'Coming To Town': 1, 'To Town #MTVHottest': 1, 'Town #MTVHottest Justin': 1, '#MTVHottest Justin Bieber\"': 1}\n",
      "\n",
      "\n",
      "are near duplicates\n",
      "2.041241452319315\n",
      "si te gusta\n",
      "te gusta Santa\n",
      "gusta Santa Claus\n",
      "Santa Claus Is\n",
      "Claus Is Coming\n",
      "Is Coming To\n",
      "Coming To Town\n",
      "To Town #MTVHottest\n",
      "Town #MTVHottest Justin\n",
      "#MTVHottest Justin Bieber\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# open file\n",
    "fp = open(\"Santa.txt\",'r')\n",
    "\n",
    "#import re\n",
    "import re\n",
    "import math\n",
    "\n",
    "\n",
    "# split each text argument and place three words into dictionaries counting up by one word\n",
    "def moving_window(text):\n",
    "    #split by spacing\n",
    "    tweet= text.split()\n",
    "    #local variables\n",
    "    a =1\n",
    "    b=2\n",
    "    tweetdict = {}\n",
    "    #for each word in text \n",
    "    for phrase in tweet:\n",
    "        # if b it is less than the length of the list\n",
    "        if b < len(tweet):\n",
    "            #assign the word in the for loop plus the two in front of it to the dictionary \n",
    "            fullphrase = phrase +\" \"+ tweet[a]+\" \"+ tweet[b]\n",
    "            a +=1\n",
    "            b  +=1\n",
    "            #assign a value of one\n",
    "            tweetdict[fullphrase]= 1\n",
    "    print()\n",
    "    #return dictionary\n",
    "    return tweetdict\n",
    "\n",
    "\n",
    "#count the number of matching keywords between two dictionaries\n",
    "def matches(dic1,dic2):\n",
    "    counter = 0 \n",
    "    #for every key phrase in the first dictionary\n",
    "    for k in dic1.keys():\n",
    "        #if that keyword exists in the second dictionary\n",
    "        if k in dic2.keys():\n",
    "            # count upwards\n",
    "                counter +=1\n",
    "    #return the number of matching phrases\n",
    "    return counter\n",
    "    \n",
    "    # returns the cosine between two dictionaries (matches/ sqrt(n1+n2))    \n",
    "def cosine(dic1, dic2):\n",
    "    #sqrt (n1+n2)\n",
    "    denominator = math.sqrt(len(dic1.keys())+len(dic2.keys()))\n",
    "    #calls matches to determine number of matches then divides by sqrt(n1+n2)\n",
    "    similarity=matches(dic1,dic2)/denominator\n",
    "    #returns cosine\n",
    "    return similarity\n",
    "\n",
    "#find the duplicates\n",
    "def find_dupli(dic1, dic2):\n",
    "    #if the dic1 does not equal dic2\n",
    "    if dic1 != dic2:\n",
    "        #find the similarity\n",
    "        similarity = cosine(dic1,dic2)\n",
    "        #if the similarity is greater than .5\n",
    "        if similarity >= 0.5:\n",
    "            #print out info statements\n",
    "            print(dic1)\n",
    "            print(dic2)\n",
    "            print('\\n')\n",
    "            print (\"are near duplicates\")\n",
    "            print(similarity)\n",
    "            \n",
    "            #print out the matching keys\n",
    "            for key in dic1.keys():\n",
    "                if key in dic2.keys():\n",
    "                    print ( key)\n",
    "                    \n",
    "            \n",
    "    \n",
    "    #Grab a list of the tweets \n",
    "def move_through_tweets():\n",
    "    #open txt file\n",
    "    fp = open(\"Santa.txt\",'r')\n",
    "    #local var\n",
    "    tweets = []\n",
    "    # for every tweet in doc\n",
    "    for line in fp:\n",
    "        #append the tweet to a list, creating a list of tweets\n",
    "        tweets.append(line)\n",
    "    #return  the list of tweets\n",
    "    return tweets\n",
    "        \n",
    "   #search through all of the tweets and print matching keys            \n",
    "def search_all():\n",
    "    #grab a list of the tweets\n",
    "    tweets = move_through_tweets()\n",
    "    #ittereate throught the length of the list\n",
    "    for i in range(len(tweets)):\n",
    "        #itterate again\n",
    "        for j in range(len(tweets)):\n",
    "            # if they are not equal\n",
    "            if i != j:\n",
    "                #grab two dictionaries of each tweet\n",
    "                tweeta = moving_window(tweets[i])\n",
    "                tweetb = moving_window(tweets[j])\n",
    "                #find the duplicates and print similarity\n",
    "                find_dupli(tweeta, tweetb)\n",
    "                #print a space\n",
    "                print('\\n')\n",
    "\n",
    "    \n",
    "search_all()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d76024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d7ab74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130bce38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1932c17b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
