{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1\n",
    "Avery Shepherd, Garret Sooter, Chandler Wann"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rock, Paper, Scissors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your move: Rock, Paper, Scissors, or Quit?: Rock\n",
      "Paper gently covers rock!! No no one can see you! you lose!\n",
      "Your move: Rock, Paper, Scissors, or Quit?: Paper\n",
      "We both chose paper Tie!\n",
      "Your move: Rock, Paper, Scissors, or Quit?: Scissors\n",
      "Scissors cut paper! You Win :(\n",
      "Your move: Rock, Paper, Scissors, or Quit?: Rock\n",
      "We both chose rock Tie!\n",
      "Your move: Rock, Paper, Scissors, or Quit?: Rock\n",
      "We both chose rock Tie!\n",
      "Your move: Rock, Paper, Scissors, or Quit?: Rock\n",
      "Paper gently covers rock!! No no one can see you! you lose!\n",
      "Your move: Rock, Paper, Scissors, or Quit?: Paper\n",
      "We both chose paper Tie!\n",
      "Your move: Rock, Paper, Scissors, or Quit?: Green\n",
      "Seems like a typo, please try again:\n",
      "Your move: Rock, Paper, Scissors, or Quit?: Green\n",
      "Seems like a typo, please try again:\n",
      "Your move: Rock, Paper, Scissors, or Quit?: Paper\n",
      "We both chose paper Tie!\n",
      "Your move: Rock, Paper, Scissors, or Quit?: Quit\n",
      "you won 1 games, and played 8 games\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "## the brains of the game\n",
    "def game(stats, Player_move):\n",
    "    possible_moves = ['rock', 'paper', 'scissors']\n",
    "    win = 0\n",
    "\n",
    "    ## Stratagy if you have chosen 1 more than 50% of the time will perdict to do so again     \n",
    "    if stats['rock'] >= (stats['paper'] + stats['scissors']):\n",
    "        My_Move = 'paper'\n",
    "    elif stats['paper'] >= (stats['rock'] + stats['scissors']):\n",
    "        My_Move = 'scissors'\n",
    "    elif stats['scissors'] >= (stats['paper'] + stats['rock']):\n",
    "        My_Move = 'rock'\n",
    "\n",
    "    ## if you have a bias towards 2 of the options then you will chose the one that will win or tie\n",
    "    elif stats['rock'] + stats['paper'] > 3*stats['scissors']:\n",
    "        My_Move = 'paper'\n",
    "    elif stats['paper'] + stats['scissors'] > 3*stats['rock']:\n",
    "        My_Move = 'scissors'\n",
    "    elif stats['rock'] + stats['scissors'] > 3*stats['paper']:\n",
    "        My_Move = 'rock'\n",
    "    else:\n",
    "        My_Move = random.choice(possible_moves)\n",
    "\n",
    "    ## Determine winner                                                                                                            \n",
    "    if  My_Move == Player_move:\n",
    "        message = f\"We both chose {Player_move} Tie!\"\n",
    "    \n",
    "    elif My_Move == \"rock\":\n",
    "        if Player_move == 'paper':\n",
    "            message = \"Paper covers rock, which really doesn't do much but I guess You Win :(\"\n",
    "            win = 1\n",
    "        else:\n",
    "            message = \"Rock crushes Scissors!! You Lose ! I cannot be beat!!\"\n",
    "\n",
    "    elif My_Move == \"paper\":\n",
    "        if Player_move == 'scissors':\n",
    "            message = \"Scissors cut paper! You Win :(\"\n",
    "            win = 1\n",
    "        else:\n",
    "            message = \"Paper gently covers rock!! No no one can see you! you lose!\"\n",
    "\n",
    "    elif My_Move == \"scissors\":\n",
    "        if Player_move == 'rock':\n",
    "            message = \"Rock crushes Scissors! gee dang, i'll get you next time\"\n",
    "            win = 1\n",
    "        else:\n",
    "            message = \"Scissors cut Paper and I turn you in to a snowflake Mwhaha!!\"\n",
    "    \n",
    "    return message, win\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "def start_game():\n",
    "    possible_moves = ['rock', 'paper', 'scissors', 'quit']\n",
    "    player_move = input('Your move: Rock, Paper, Scissors, or Quit?: ').lower()\n",
    "    won = 0\n",
    "    played = 0\n",
    "    stats = {'rock': 1, 'paper': 1, 'scissors': 1}\n",
    "## Make sure input is valid\n",
    "    while 0 == 0:\n",
    "        while player_move not in possible_moves:\n",
    "            print(\"Seems like a typo, please try again:\")\n",
    "            player_move = input('Your move: Rock, Paper, Scissors, or Quit?: ').lower()\n",
    "## allow to quit and send printout\n",
    "        if player_move == \"quit\":\n",
    "            print(\"you won\", won, \"games, and played\", played, \"games\")\n",
    "            return\n",
    "## run game and allow game to take into account human bias\n",
    "        else:\n",
    "            message, win = game(stats, player_move)\n",
    "            print(message)\n",
    "            won += win\n",
    "            stats[player_move] += 1\n",
    "            played += 1\n",
    "            player_move = input('Your move: Rock, Paper, Scissors, or Quit?: ').lower()\n",
    "    \n",
    "    \n",
    "start_game()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voters in Florida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('LAFAYETTE', 1373, 2672), ('GLADES', 2190, 3110), ('LIBERTY', 720, 3372), ('UNION', 2752, 3579), ('GILCHRIST', 5789, 3652), ('FRANKLIN', 2234, 4319), ('HOLMES', 5282, 4434), ('GULF', 4234, 4521), ('HARDEE', 4859, 4702), ('HAMILTON', 2154, 4796), ('DIXIE', 3314, 4839), ('CALHOUN', 2201, 5324), ('WASHINGTON', 7101, 5687), ('JEFFERSON', 2636, 5802), ('BAKER', 6963, 5813), ('BRADFORD', 6878, 6533), ('TAYLOR', 3950, 6915), ('MADISON', 2992, 7158), ('DESOTO', 4870, 7181), ('OKEECHOBEE', 7755, 7756), ('HENDRY', 5862, 7999), ('WAKULLA', 7374, 8889), ('LEVY', 11665, 9509), ('WALTON', 25609, 10013), ('SUWANNEE', 10745, 11126), ('NASSAU', 32958, 14013), ('COLUMBIA', 15790, 14797), ('JACKSON', 9626, 15706), ('MONROE', 20602, 17614), ('HIGHLANDS', 27100, 19997), ('PUTNAM', 17067, 20606), ('GADSDEN', 4372, 22161), ('SUMTER', 47158, 22977), ('FLAGLER', 30047, 24734), ('OKALOOSA', 75154, 25172), ('SANTA ROSA', 73627, 26114), ('MARTIN', 53800, 27358), ('INDIAN RIVER', 47794, 28204), ('CITRUS', 46373, 30440), ('BAY', 57456, 30733), ('CLAY', 76584, 31285), ('CHARLOTTE', 54421, 35602), ('ST. JOHNS', 88385, 39531), ('HERNANDO', 51254, 42499), ('COLLIER', 100167, 45511), ('LAKE', 93604, 67237), ('MANATEE', 96063, 67926), ('ESCAMBIA', 90265, 70180), ('OSCEOLA', 44594, 75657), ('ST. LUCIE', 59626, 76163), ('MARION', 97306, 76268), ('ALACHUA', 47329, 77996), ('SARASOTA', 125872, 89711), ('SEMINOLE', 107833, 91686), ('LEON', 54554, 103140), ('PASCO', 125305, 104324), ('LEE', 180718, 114633), ('VOLUSIA', 121402, 124136), ('BREVARD', 167129, 127435), ('POLK', 140619, 143799), ('PINELLAS', 223077, 221968), ('DUVAL', 210195, 229501), ('ORANGE', 206174, 303458), ('HILLSBOROUGH', 257436, 314265), ('PALM BEACH', 245452, 367236), ('MIAMI-DADE', 362161, 539367), ('BROWARD', 249762, 566185), ('Total', 4377713, 4637026)]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# opens voters html, matches and strips to be just text and returns a list of all text\n",
    "def read_file():\n",
    "    fp = open(\"FloridaVoters.html\", \"r\")\n",
    "    \n",
    "    text = []\n",
    "    for line in fp:\n",
    "        if re.match(\"<td>\\w+[,-\\.]?[\\d,]*[\\s]?\\w+</td>\", line) is not None:\n",
    "            line = line.strip(\"<td>\").strip(\"\\n\").rstrip(\"</td>\")\n",
    "            line = line.replace(\",\", \"\")\n",
    "            text.append(line)\n",
    "    fp.close()\n",
    "    return text\n",
    "\n",
    "# takes in list of all text and extracts county, and dem and republican voters\n",
    "# turns voters into integers \n",
    "def clean_text(text):\n",
    "    voters = []\n",
    "    for i in range(0, len(text), 6):\n",
    "        voters.append((text[i], int(text[i+1]), int(text[i+2])))\n",
    "    return voters\n",
    "\n",
    "# creates key so that voters can be sorted by democrat\n",
    "def dem_key(voters):\n",
    "    return voters[2]\n",
    "        \n",
    "\n",
    "text = read_file()\n",
    "voters = clean_text(text)\n",
    "# sorts by democrats \n",
    "voters = sorted(voters, key = dem_key)\n",
    "print(voters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Near-duplicate detection\n",
    "### (a) Convert each tweet into a dictionary of phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RT @BuyBookstore: SPECIAL': 1,\n",
       " '@BuyBookstore: SPECIAL SECRET': 1,\n",
       " 'SPECIAL SECRET HEARTS:': 1,\n",
       " 'SECRET HEARTS: A': 1,\n",
       " \"HEARTS: A Child's\": 1,\n",
       " \"A Child's Introduction\": 1,\n",
       " \"Child's Introduction to\": 1,\n",
       " 'Introduction to Dementia': 1,\n",
       " 'to Dementia and': 1,\n",
       " 'Dementia and Pink': 1,\n",
       " 'and Pink Curls': 1,\n",
       " 'Pink Curls -': 1,\n",
       " 'Curls - A': 1,\n",
       " '- A Santa': 1,\n",
       " 'A Santa ...': 1,\n",
       " 'Santa ... -': 1,\n",
       " '... - http://t.co/UWCdc8FA9a': 1,\n",
       " '- http://t.co/UWCdc8FA9a http://t.': 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import math\n",
    "\n",
    "\n",
    "# split each text argument and place three words into dictionaries counting up by one word\n",
    "def moving_window(text):\n",
    "    #split by spacing\n",
    "    tweet= text.split()\n",
    "    #local variables\n",
    "    a =1\n",
    "    b=2\n",
    "    tweetdict = {}\n",
    "    #for each word in text \n",
    "    for phrase in tweet:\n",
    "        # if b it is less than the length of the list\n",
    "        if b < len(tweet):\n",
    "            #assign the word in the for loop plus the two in front of it to the dictionary \n",
    "            fullphrase = phrase +\" \"+ tweet[a]+\" \"+ tweet[b]\n",
    "            a +=1\n",
    "            b  +=1\n",
    "            #assign a value of one\n",
    "            tweetdict[fullphrase]= 1\n",
    "    print()\n",
    "    #return dictionary\n",
    "    return tweetdict\n",
    "\n",
    "def move_through_tweets():\n",
    "    #open txt file\n",
    "    fp = open(\"Santa.txt\",'r')\n",
    "    #local var\n",
    "    tweets = []\n",
    "    # for every tweet in doc\n",
    "    for line in fp:\n",
    "        #append the tweet to a list, creating a list of tweets\n",
    "        tweets.append(line)\n",
    "    #return  the list of tweets\n",
    "    return tweets\n",
    "\n",
    "\n",
    "\n",
    "tweets = move_through_tweets()\n",
    "moving_window(tweets[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Calculate similarity between two tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.5724787771376323"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number of matching keywords between two dictionaries\n",
    "def matches(dic1,dic2):\n",
    "    counter = 0 \n",
    "    #for every key phrase in the first dictionary\n",
    "    for k in dic1.keys():\n",
    "        #if that keyword exists in the second dictionary\n",
    "        if k in dic2.keys():\n",
    "            # count upwards\n",
    "                counter +=1\n",
    "    #return the number of matching phrases\n",
    "    return counter\n",
    "    \n",
    "# returns the cosine between two dictionaries (matches/ sqrt(n1+n2))    \n",
    "def cosine(dic1, dic2):\n",
    "    #sqrt (n1+n2)\n",
    "    denominator = math.sqrt(len(dic1.keys())+len(dic2.keys()))\n",
    "    #calls matches to determine number of matches then divides by sqrt(n1+n2)\n",
    "    similarity=matches(dic1,dic2)/denominator\n",
    "    #returns cosine\n",
    "    return similarity\n",
    "\n",
    "cosine(moving_window(tweets[0]), moving_window(tweets[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Read in tweets, and output near-duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'SPECIAL SECRET HEARTS:': 1, 'SECRET HEARTS: A': 1, \"HEARTS: A Child's\": 1, \"A Child's Introduction\": 1, \"Child's Introduction to\": 1, 'Introduction to Dementia': 1, 'to Dementia and': 1, 'Dementia and Pink': 1, 'and Pink Curls': 1, 'Pink Curls -': 1, 'Curls - A': 1, '- A Santa': 1, 'A Santa ...': 1, 'Santa ... -': 1, '... - http://t.co/UWCdc8FA9a': 1, '- http://t.co/UWCdc8FA9a http://t.co/meexKLGTKl': 1}\n",
      "{'RT @BuyBookstore: SPECIAL': 1, '@BuyBookstore: SPECIAL SECRET': 1, 'SPECIAL SECRET HEARTS:': 1, 'SECRET HEARTS: A': 1, \"HEARTS: A Child's\": 1, \"A Child's Introduction\": 1, \"Child's Introduction to\": 1, 'Introduction to Dementia': 1, 'to Dementia and': 1, 'Dementia and Pink': 1, 'and Pink Curls': 1, 'Pink Curls -': 1, 'Curls - A': 1, '- A Santa': 1, 'A Santa ...': 1, 'Santa ... -': 1, '... - http://t.co/UWCdc8FA9a': 1, '- http://t.co/UWCdc8FA9a http://t.': 1}\n",
      "are near duplicates with similarity of: 2.5724787771376323\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'\"Santa Claus Is': 1, 'Claus Is Coming': 1, 'Is Coming To': 1, 'Coming To Town': 1, 'To Town #MTVHottest': 1, 'Town #MTVHottest Justin': 1, '#MTVHottest Justin Bieber\"': 1}\n",
      "{'\"RT @DrewFtDevonne_: Rt': 1, '@DrewFtDevonne_: Rt si': 1, 'Rt si te': 1, 'si te gusta': 1, 'te gusta Santa': 1, 'gusta Santa Claus': 1, 'Santa Claus Is': 1, 'Claus Is Coming': 1, 'Is Coming To': 1, 'Coming To Town': 1, 'To Town #MTVHottest': 1, 'Town #MTVHottest Justin': 1, '#MTVHottest Justin Bieber\"': 1}\n",
      "are near duplicates with similarity of: 1.3416407864998738\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'\"Santa Claus Is': 1, 'Claus Is Coming': 1, 'Is Coming To': 1, 'Coming To Town': 1, 'To Town #MTVHottest': 1, 'Town #MTVHottest Justin': 1, '#MTVHottest Justin Bieber\"': 1}\n",
      "{'\"Rt si te': 1, 'si te gusta': 1, 'te gusta Santa': 1, 'gusta Santa Claus': 1, 'Santa Claus Is': 1, 'Claus Is Coming': 1, 'Is Coming To': 1, 'Coming To Town': 1, 'To Town #MTVHottest': 1, 'Town #MTVHottest Justin': 1, '#MTVHottest Justin Bieber\"': 1}\n",
      "are near duplicates with similarity of: 1.4142135623730951\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'RT @BuyBookstore: SPECIAL': 1, '@BuyBookstore: SPECIAL SECRET': 1, 'SPECIAL SECRET HEARTS:': 1, 'SECRET HEARTS: A': 1, \"HEARTS: A Child's\": 1, \"A Child's Introduction\": 1, \"Child's Introduction to\": 1, 'Introduction to Dementia': 1, 'to Dementia and': 1, 'Dementia and Pink': 1, 'and Pink Curls': 1, 'Pink Curls -': 1, 'Curls - A': 1, '- A Santa': 1, 'A Santa ...': 1, 'Santa ... -': 1, '... - http://t.co/UWCdc8FA9a': 1, '- http://t.co/UWCdc8FA9a http://t.': 1}\n",
      "{'SPECIAL SECRET HEARTS:': 1, 'SECRET HEARTS: A': 1, \"HEARTS: A Child's\": 1, \"A Child's Introduction\": 1, \"Child's Introduction to\": 1, 'Introduction to Dementia': 1, 'to Dementia and': 1, 'Dementia and Pink': 1, 'and Pink Curls': 1, 'Pink Curls -': 1, 'Curls - A': 1, '- A Santa': 1, 'A Santa ...': 1, 'Santa ... -': 1, '... - http://t.co/UWCdc8FA9a': 1, '- http://t.co/UWCdc8FA9a http://t.co/meexKLGTKl': 1}\n",
      "are near duplicates with similarity of: 2.5724787771376323\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'\"RT @DrewFtDevonne_: Rt': 1, '@DrewFtDevonne_: Rt si': 1, 'Rt si te': 1, 'si te gusta': 1, 'te gusta Santa': 1, 'gusta Santa Claus': 1, 'Santa Claus Is': 1, 'Claus Is Coming': 1, 'Is Coming To': 1, 'Coming To Town': 1, 'To Town #MTVHottest': 1, 'Town #MTVHottest Justin': 1, '#MTVHottest Justin Bieber\"': 1}\n",
      "{'\"Santa Claus Is': 1, 'Claus Is Coming': 1, 'Is Coming To': 1, 'Coming To Town': 1, 'To Town #MTVHottest': 1, 'Town #MTVHottest Justin': 1, '#MTVHottest Justin Bieber\"': 1}\n",
      "are near duplicates with similarity of: 1.3416407864998738\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'\"RT @DrewFtDevonne_: Rt': 1, '@DrewFtDevonne_: Rt si': 1, 'Rt si te': 1, 'si te gusta': 1, 'te gusta Santa': 1, 'gusta Santa Claus': 1, 'Santa Claus Is': 1, 'Claus Is Coming': 1, 'Is Coming To': 1, 'Coming To Town': 1, 'To Town #MTVHottest': 1, 'Town #MTVHottest Justin': 1, '#MTVHottest Justin Bieber\"': 1}\n",
      "{'\"Rt si te': 1, 'si te gusta': 1, 'te gusta Santa': 1, 'gusta Santa Claus': 1, 'Santa Claus Is': 1, 'Claus Is Coming': 1, 'Is Coming To': 1, 'Coming To Town': 1, 'To Town #MTVHottest': 1, 'Town #MTVHottest Justin': 1, '#MTVHottest Justin Bieber\"': 1}\n",
      "are near duplicates with similarity of: 2.041241452319315\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'\"Rt si te': 1, 'si te gusta': 1, 'te gusta Santa': 1, 'gusta Santa Claus': 1, 'Santa Claus Is': 1, 'Claus Is Coming': 1, 'Is Coming To': 1, 'Coming To Town': 1, 'To Town #MTVHottest': 1, 'Town #MTVHottest Justin': 1, '#MTVHottest Justin Bieber\"': 1}\n",
      "{'\"Santa Claus Is': 1, 'Claus Is Coming': 1, 'Is Coming To': 1, 'Coming To Town': 1, 'To Town #MTVHottest': 1, 'Town #MTVHottest Justin': 1, '#MTVHottest Justin Bieber\"': 1}\n",
      "are near duplicates with similarity of: 1.4142135623730951\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'\"Rt si te': 1, 'si te gusta': 1, 'te gusta Santa': 1, 'gusta Santa Claus': 1, 'Santa Claus Is': 1, 'Claus Is Coming': 1, 'Is Coming To': 1, 'Coming To Town': 1, 'To Town #MTVHottest': 1, 'Town #MTVHottest Justin': 1, '#MTVHottest Justin Bieber\"': 1}\n",
      "{'\"RT @DrewFtDevonne_: Rt': 1, '@DrewFtDevonne_: Rt si': 1, 'Rt si te': 1, 'si te gusta': 1, 'te gusta Santa': 1, 'gusta Santa Claus': 1, 'Santa Claus Is': 1, 'Claus Is Coming': 1, 'Is Coming To': 1, 'Coming To Town': 1, 'To Town #MTVHottest': 1, 'Town #MTVHottest Justin': 1, '#MTVHottest Justin Bieber\"': 1}\n",
      "are near duplicates with similarity of: 2.041241452319315\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#find the duplicates\n",
    "def find_dupli(dic1, dic2):\n",
    "    #if the dic1 does not equal dic2\n",
    "    if dic1 != dic2:\n",
    "        #find the similarity\n",
    "        similarity = cosine(dic1,dic2)\n",
    "        #if the similarity is greater than .5\n",
    "        if similarity >= 0.5:\n",
    "            #print out info statements\n",
    "            print(dic1)\n",
    "            print(dic2)\n",
    "            print (\"are near duplicates with similarity of:\", similarity)\n",
    "\n",
    "def search_all():\n",
    "    #grab a list of the tweets\n",
    "    tweets = move_through_tweets()\n",
    "    #ittereate throught the length of the list\n",
    "    for i in range(len(tweets)):\n",
    "        #itterate again\n",
    "        for j in range(len(tweets)):\n",
    "            # if they are not equal\n",
    "            if i != j:\n",
    "                #grab two dictionaries of each tweet\n",
    "                tweeta = moving_window(tweets[i])\n",
    "                tweetb = moving_window(tweets[j])\n",
    "                #find the duplicates and print similarity\n",
    "                find_dupli(tweeta, tweetb)\n",
    "                #print a space\n",
    "                print('\\n')\n",
    "                \n",
    "                \n",
    "search_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google of Quotes \n",
    "### (a) Build a list of full quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['How we spend our days is, of course, how we spend our lives. - Annie Dillard', 'Two roads diverged in a wood, and I...I took the one less traveled by, and that has made all the difference. - Robert Frost', 'What is happiness? The feeling that power is growing, that resistance is overcome. - Friedrich Nietzsche', 'A great deal of intelligence can be invested in ignorance when the need for illusion is deep. - Saul Bellow', 'Those who are preoccupied with `making a statement` usually don`t have any statements worth making. - Thomas Sowell']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import math\n",
    "\n",
    "# reads in file, stripping new lines\n",
    "def read_file():\n",
    "    fp = open(\"quotes.txt\", \"r\", encoding = \"ISO-8859-1\")\n",
    "    text = []\n",
    "    for line in fp:\n",
    "        if line == '':\n",
    "            pass\n",
    "        else:\n",
    "            text.append(line.strip(\"\\n\"))\n",
    "    return text\n",
    "\n",
    "# concatenates all quotes and speaker with a '-'\n",
    "def clean_quotes(text):\n",
    "    quotes = []\n",
    "    for i in range(0, len(text), 2):\n",
    "        q = text[i] + \" - \" + text[i+1]\n",
    "        quotes.append(q)\n",
    "    return quotes\n",
    "\n",
    "text = read_file()\n",
    "quotes = clean_quotes(text)\n",
    "print(quotes[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Words from full quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['how', 'we', 'spend', 'our', 'days', 'is', 'of', 'course', 'how', 'we', 'spend', 'our', 'lives', 'annie', 'dillard']\n"
     ]
    }
   ],
   "source": [
    "# splits quotes into a list\n",
    "def split_quote(quote):\n",
    "    quote = quote.lower()\n",
    "    quote = quote.replace(\"`\", \"\")\n",
    "    words = re.split(\"[^'\\w_']+\", quote)\n",
    "\n",
    "    return words\n",
    "\n",
    "print(split_quote(quotes[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Build the postings-list dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'how': 2, 'we': 2, 'spend': 2, 'our': 2, 'days': 1, 'is': 1, 'of': 1, 'course': 1, 'lives': 1, 'annie': 1, 'dillard': 1}\n"
     ]
    }
   ],
   "source": [
    "# quote into numbered dictionary\n",
    "def quote_dict(quote):\n",
    "    words = split_quote(quote)\n",
    "    lib = dict()\n",
    "    for w in words:\n",
    "        if w not in lib:\n",
    "            lib[w] = 1\n",
    "        else:\n",
    "            lib[w] += 1\n",
    "    return lib\n",
    "\n",
    "# turn all text into dictionary with words as values\n",
    "def postings_dict(quotes):\n",
    "    postings = dict()\n",
    "    for q in quotes:\n",
    "        postings[q] = quote_dict(q)\n",
    "    return postings\n",
    "\n",
    "\n",
    "postings = postings_dict(quotes)\n",
    "print(postings['How we spend our days is, of course, how we spend our lives. - Annie Dillard'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Build the reverse postings-list dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'In any fairly large and talkative community such as a university there is always the danger that those who think alike should gravitate together where they will henceforth encounter opposition only in the emasculated form of rumour that the outsiders say thus and thus. The absent are easily refuted, complacent dogmatism thrives, and differences of opinion are embittered by the group hostility. Each group hears not the best, but the worst, that the other group can say. - C.S. Lewis': 2,\n",
       " 'Genius may have its limitations, but stupidity is not thus handicapped. - Elbert Hubbard': 1,\n",
       " 'Thus the metric system did not really catch on in the States, unless you count the increasing popularity of the nine-millimeter bullet. - Dave Barry': 1,\n",
       " 'It is always thus, impelled by a state of mind which is destined not to last, that we make our irrevocable decisions. - Marcel Proust': 1,\n",
       " 'Thus far, the reputed idiot Bush has graduated from Yale and Harvard, made a stack of cash in the oil industry, become the first consecutive-term governor of Texas, defeated a dual-term VP for the presidency, and led his party to [November 5th`s] extraordinary triumphs. Let his opponents keep calling him stupid; if they do, within five years Bush will be King of England, the Pope, and world Formula One motor racing champion. - Tim Blair': 1,\n",
       " 'Science is not about building a body of known `facts`. It is a method for asking awkward questions and subjecting them to a reality-check, thus avoiding the human tendency to believe whatever makes us feel good. - Terry Pratchett': 1,\n",
       " 'This does not mean that the enemy is to be allowed to escape. The object is to make him believe that there is a road to safety, and thus prevent his fighting with the courage of despair. After that, you may crush him. - Sun Tzu': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reverse_postings(postings):\n",
    "    reverse_postings = dict()\n",
    "    \n",
    "    for p in postings:\n",
    "        for key, value in postings[p].items():\n",
    "            if key in reverse_postings:\n",
    "                reverse_postings[key][p] = value\n",
    "            else:\n",
    "                reverse_postings[key] = {p: value}\n",
    "    return reverse_postings\n",
    "\n",
    "rev_postings = reverse_postings(postings)\n",
    "rev_postings[\"thus\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) Write a TF-IDF function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "6.786716950605081\n",
      "3.3933584753025405\n"
     ]
    }
   ],
   "source": [
    "def term_freq(word, quote, postings):\n",
    "    word_count = postings[quote][word]\n",
    "    max_count = max(postings[quote].values())\n",
    "    \n",
    "    return word_count / max_count\n",
    "\n",
    "print(term_freq(\"entertainer\", \"An actor is at most a poet and at least an entertainer. - Marlon Brando\", postings))\n",
    "\n",
    "def inv_doc_freq(word, rev_postings, postings):\n",
    "    n_quotes = len(postings)\n",
    "    w_quotes = len(rev_postings[word])\n",
    "    \n",
    "    return math.log(n_quotes / w_quotes)\n",
    "    \n",
    "print(inv_doc_freq(\"entertainer\", rev_postings, postings))\n",
    "\n",
    "\n",
    "def tf_idf(word, quote, rev_postings, postings):\n",
    "    return inv_doc_freq(word, rev_postings, postings) * term_freq(word, quote, postings)\n",
    "\n",
    "print(tf_idf(\"entertainer\", \"An actor is at most a poet and at least an entertainer. - Marlon Brando\", rev_postings, postings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (f) Quote search using a single word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'An actor is at most a poet and at least an entertainer. - Marlon Brando': 3.3933584753025405}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def quote_search(word, rev_postings, postings):\n",
    "    search_dict = dict()\n",
    "    \n",
    "    for quote in rev_postings[word]:\n",
    "        search_dict[quote] = tf_idf(word, quote, rev_postings, postings)\n",
    "    \n",
    "    return search_dict\n",
    "    \n",
    "quote_search(\"entertainer\", rev_postings, postings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (g) Quote search using multiple words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A grandmother pretends she doesn`t know who you are on Halloween. - Erna Bombeck': 6.093569770045136,\n",
       " 'There is nothing funny about Halloween. This sarcastic festival reflects, rather, an infernal demand for revenge by children on the adult world. - Jean Baudrillard': 11.270848808216115,\n",
       " 'There is hope for the future because God has a sense of humor and we are funny to God. - Bill Cosby': 2.5886395190854903,\n",
       " 'The most exciting phrase to hear in science, the one that heralds new discoveries, is not `Eureka!` (I found it!) but `That`s funny...` - Isaac Asimov': 2.5886395190854903,\n",
       " 'To me, clowns aren`t funny. In fact, they`re kinda scary. I`ve wondered where this started, and I think it goes back to the time I went to the circus and a clown killed my dad. - Jack Handey': 1.7257596793903267,\n",
       " 'Life does not cease to be funny when people die any more than it ceases to be serious when people laugh. - George Bernard Shaw': 2.5886395190854903}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def multi_quote_search(words, rev_postings, postings):\n",
    "    search_dict = dict()\n",
    "    \n",
    "    for w in words:\n",
    "        for quote in rev_postings[w]:\n",
    "            if quote not in search_dict:\n",
    "                search_dict[quote] = tf_idf(w, quote, rev_postings, postings)\n",
    "            else:\n",
    "                search_dict[quote] += tf_idf(w, quote, rev_postings, postings)\n",
    "    \n",
    "    return search_dict\n",
    "\n",
    "multi_quote_search([\"halloween\", \"funny\"], rev_postings, postings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
